## Meine Gedanken zum Anfang des Semesters

## !!!Noch in Arbeit!!!

Im Rahmen des Moduls KI1 sollen wir unsere bisherigen Gedanken und Meinung zur Künstlichen Intelligenz festhalten, was ich mit diesem Blogeintrag machen will. Dazu hatten wir zwei Artikel zu lesen um einmal einen groben Einblick in die Thematik zu erhalten.
Ich wusste zwar bis jetzt schon dass ich immer wieder im alltäglichen Leben mit KIs zu tun habe, doch nicht in diesem Ausmass. Ich habe eher gedacht im Internet mit Bezug auf die Big Five, Big Data usw. und mir einen ominösen Supercomputer vorgestellt. Und als ich meine Informatik Lehre begonnen habe eher etwas in Richtung IRobot :P

### KI Kaliber
Es gibt nämlich verschiedene Grössenordnungen von KIs und zwar wie im Wait But Why – The Artificial Intelligence Revolution Artikel erwähnt 3. Die Artificial Narrow Intelligence (ANI), welche spezialisiert auf nur einen Task ist, also zum Beispiel den besten Schach Spieler der Welt im Schach schlagen. Aber wenn man ihn fragt wie das Wetter heute wird, wird man kaum eine Antwort, geschweige denn eine gescheite Antwort bekommen. Artifical General Intelligence (AGI), auch Human-Level AI genannt, meint einen Computer der jede intellektuell anspruchsvolle Aufgabe, im Ergebnis wie ein Mensch lösen kann. Dann gibt es noch die Artificial Superintelligence (ASI), damit ist eine KI gemeint die besser als ein Mensch ist, das reicht von ein wenig intelligenter als ein Mensch bis hinzu Trillionen Mal besser als ein Mensch, so das er z.B. zu jedem Zeitpunkt weiss wo welches Atom in unserem Universum ist usw.
Ich hatte bis anhin nicht gedacht das ANI Systeme auch zu KIs gehören, wie die Benzineinspritzung von Autos, selbstfahrende Autos oder das mein Smartphone voll von ANIs ist wie auch Spamfilter und so weiter.

### Probleme für Sprung ANI -> AGI
#### HW-Problem
Wie gerade gesagt ist eigentlich die erste Stufe der KIs schon erreicht, jetzt gilt es den Sprung von ANI zu AGI zu schaffen. Dafür muss aber zuerst die Computerleistung um einiges erhöht werden, wenn man nur schon daran denkt, das eine AGI unzählige Sensoren benötigt um unsere Sinne nachzuahmen, welche eine schier unmöglich verarbeitbare Menge von Daten liefern und diese dann auch noch sinnvoll verarbeitet werden sollen. Zudem sollte diese Computerpower auch einigermassen bezahlbar sein, wenn AGI nicht nur von einigen wenigen verwendet werden soll. Und diese Rechenpower darf nicht zu viel Platz verbrauchen, da man sonst an Lokalitäten gebunden ist.
Die nötige Computerpower wurde zwar schon erreicht durch Chinas Tianhe-2 mit 34 Quadrillionen CPS. Braucht jedoch 720 Quadratmeter Platz, 24 Megawatt Energie und kostet 390 Millionen Dollar um gebaut zu werden. Dieses Problem mit der Leistung wird sich aber nach Moore’s Law, wie ich denke, von „alleine“ Lösen.

#### "Be smart"-Problem
Das meiner Meinung nach grössere Problem das es zu lösen gibt, ist es die KI „smart“ zu machen. Denn das mit der Computer Power wird sich sowieso irgendwann lösen. Dafür gibt es verschiedene Ansätze mit Beispiel zum Klassenkollegen der immer besser ist als man selber und man auch so gut sein will:

1. Das Gehirn zu „kopieren“ – Die Antworten vom Nachbarn kopieren
2. Die Evolution nachahmen – Lernen wie der Nachbar für den Test lernt.
3. Dieses ganze Zeug zum Problem des Computer machen, nicht unseres.

Der 1. Ansatz ist zurzeit ziemlich schwierig zu erreichen, denn wir verstehen die Funktionsweise unseres Gehirns nur Ansatzweise und wir müssten es dafür zuerst ganz verstehen, was noch lange dauern kann. Das Problem des 2. Ansatzes ist, dass es wie bei unserer Evolution Millionen von Jahren dauern kann. Man kann dies zwar durch Einschränkungen verkürzen, wird aber wahrscheinlich trotzdem immer noch viel zu lange dauern. Es könnte aber auch sein dass es mit viel Glück gar nicht so lange gehen wird. Der bis anhin wahrscheinlich beste Ansatz ist der 3., also dass wir unser Problem, zum Problem des Computers machen. Also dass wir ihm beibringen sich selbst zu einer AGI zu machen. Also einen Computer zu erstellen dessen Aufgabe es ist, Nachforschungen über KIs anzustellen und sich selbst umzuprogrammieren und zu verbessern.


### Ausblick

Was ich an der ganzen KI Geschichte auch sehr spannend finde, sind die ganzen ethischen Fragen? Also wie kann man verhindern dass eine ASI die ganze Menschheit auslöscht, weil sie die Aufgabe bekam die Welt zu „beschützen“ oder sich anfängt selbstständig zu machen. Was soll ein selbstfahrendes Auto machen? Welches Leben hat mehr wert? Das des einen Passagiers oder dessen die auf dem Fussgänger stehen oder im anderen Auto sitzen. Frage an den Leser? Was würdest du für ein Auto kaufen, eines dass die Anzahl toten auf jeden Fall minimiert oder immer die Insassen am besten schützt? Oder wenn man wie beim 3. Ansatz dem Computer beibringt sich selber umzuschreiben und zu verbessern, wie behält man die Kontrolle dass er sich zum positiven verbessert?
Also die ganze Frage wie Sicherheitsmechanismen implementiert werden können um IRobot Szenarien zu verhindern.

Oder auch Fragen wie zu extreme Übervorteilung verhindert werden kann? (Was währe wenn the "Rocket Man" als erster eine ASI entwickelt?)


Es sind mir noch unzählige Fragen offen für dieses Modul, wie z.B. man ein neuronales Netzwerk nachahmt mit Transistoren, wie man das ganze KI Zeug programmiert, wie man die ganze Umgebung mathematisch mit Sensoren ausreichend erfassen kann und sie dann auch sinnvoll auwerten kann, in anbetracht der riesen Mengen an Daten, von denen wahrscheinlich sehr viele nicht von Nutzen sind und herausgefiltert werden müssen.


## !!!Noch in Arbeit!!!
